<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>logic API documentation</title>
<meta name="description" content="This module contains all the logic required to execute
sbelt simulations/runs. All functions/classes are designed
for internal use and may change â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>logic</code></h1>
</header>
<section id="section-intro">
<p>This module contains all the logic required to execute
sbelt simulations/runs. All functions/classes are designed
for internal use and may change without note.</p>
<p>A primary purpose of this module is to manipulate n-7 NumPy
arrays which represent multiple stream particles. In these
n-7 arrays, a <em>single</em> particle is represented by a NumPy array
with 7 attributes::</p>
<pre><code>[x_location, diam, y_location, UID, active state, age, loop age]
</code></pre>
<p>In this general example, x_location and y_location define the centre point of
spherical particle whose diameter is defined by diam. See the project docs for
more information on the other attributes.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34; 
This module contains all the logic required to execute
sbelt simulations/runs. All functions/classes are designed 
for internal use and may change without note.

A primary purpose of this module is to manipulate n-7 NumPy 
arrays which represent multiple stream particles. In these
n-7 arrays, a _single_ particle is represented by a NumPy array 
with 7 attributes::

    [x_location, diam, y_location, UID, active state, age, loop age]

In this general example, x_location and y_location define the centre point of 
spherical particle whose diameter is defined by diam. See the project docs for
more information on the other attributes. 
&#34;&#34;&#34;

import math
import random
import numpy as np


import logging
logging.getLogger(__name__)


class Subregion():
    &#34;&#34;&#34; A subregion in the stream.
    
    A Subregion is defined by left (upstream)
    and right (downstream) boundaries. Each
    subregion maintains a NumPy list which is 
    used to record the number of model particles that 
    pass the downstream boundary in a given iteration. 
    For example::

        flux_list = [0,3,2,1]

    Means that 0 crossings happened in the first iteration, 
    3 happened in the 2nd, and so on. The list has 
    length equal to the number of iterations for a model run.
    
    Attributes:
        name: Name of the subregion.
        left_boundary: Location of the left boundary (float).
        right_boundary: Location of the right boundary (float).
        iterations: The number of iterations for the model run.
    &#34;&#34;&#34;
    def __init__(self, name, left_boundary, right_boundary, iterations):
        self.name = name
        self.left_boundary = left_boundary
        self.right_boundary = right_boundary
        self.flux_list = np.zeros(iterations, dtype=np.int64)
        
    def leftBoundary(self):
        &#34;&#34;&#34;Returns subregion&#39;s left boundary&#34;&#34;&#34;
        return self.left_boundary
    
    def rightBoundary(self):
        &#34;&#34;&#34;Returns subregion&#39;s right boundary&#34;&#34;&#34;
        return self.right_boundary
    
    def getName(self):
        &#34;&#34;&#34;Returns subregion&#39;s name&#34;&#34;&#34;
        return self.name

    def incrementFlux(self, iteration):
        &#34;&#34;&#34;Increments flux list by 1.

        Args:
            iteration: The iteration/index to increment by 1
        &#34;&#34;&#34;
        self.flux_list[iteration] += 1
    
    def getFluxList(self):
        &#34;&#34;&#34;Returns subregion&#39;s flux list&#34;&#34;&#34;
        return self.flux_list

def get_event_particles(e_events, subregions, model_particles, level_limit, height_dependant=False):
    &#34;&#34;&#34; Find and return list of particles to be entrained

    Will loop through each subregion and select n = e_events
    model particles (within a subregion boundaries) at random 
    to be entrained. No particle will be selected twice.

    Args:
        e_events: The number of events requested per subregion (int).
        subregions: Python array of initialized Subregion objects. 
        model_particles: An n-7 NumPy array representing the stream&#39;s n 
            model particles.

    Returns:
        event_particles: A NumPy array of k uids representing the model particles
            that have been selected for entrainment. For example::

                [2.0, 5.0, 25.0]

            Will represent that model particles with uids 2.0, 5.0 and
            25.0 have been selected for entrainment. 
    &#34;&#34;&#34;
    if e_events == 0:
        e_events = 1 #???
    
    event_particles = []
    for subregion in subregions:
        # Take only particles in the boundaries of the current subregion
        subregion_particles = model_particles[
                (model_particles[:,0] &gt;= subregion.leftBoundary())
              &amp; (model_particles[:,0] &lt;= subregion.rightBoundary())]
        # Take only particles that are in-stream (not ghost)
        in_stream_particles = subregion_particles[
                                                subregion_particles[:,0] != -1]
        # Take only particles that are &#39;active&#39; 
        active_particles =  in_stream_particles[
                                                in_stream_particles[:,4] != 0]

        # Do not take any particles that have been selected for entrainment (i.e do not double select)
        # This only happens when particles rest on the boundary. 
        active_event, active_idx, event_idx = np.intersect1d(active_particles[:,3], event_particles, return_indices=True)
        active_particles = np.delete(active_particles, active_idx, axis=0)

        subregion_event_ids = []  
        if height_dependant: # any particle at the level limit must be entrained
            levels = elevation_list(subregion_particles[:,2], desc=False)
            tip_particles = []
            # find the tip particles -- these are the particles being entrained
            if len(levels) == level_limit: 
                tip_particles = active_particles[active_particles[:,2] == levels[level_limit-1]]
            for particle in tip_particles:
                subregion_event_ids.append(particle[3])
                active_particles = active_particles[active_particles[:,2] != particle[2]]
        # If there are not enough particles in the subregion to sample from, alter the sample size
        if e_events &gt; len(active_particles):
            random_sample = random.sample(range(len(active_particles)), 
                                        len(active_particles))
        else: 
            random_sample = random.sample(range(len(active_particles)), 
                                        e_events)
        # TODO: change so that we don&#39;t rely on loop index to grab particle
        for index in random_sample:
            subregion_event_ids.append(int(active_particles[index][3])  )
        
        ghost_particles = np.where(model_particles[:,0] == -1)[0]
        for index in ghost_particles:
            model_particles[index][0] = 0 
            subregion_event_ids.append(index)
        
        if e_events != len(subregion_event_ids):
            msg = (
                     f&#39;Requested {e_events} events in {subregion.getName()} &#39; 
                     f&#39;but {len(subregion_event_ids)} are occuring&#39;
            )
            logging.info(msg)
        event_particles = event_particles + subregion_event_ids
    event_particles = np.array(event_particles, dtype=np.intp)

    return event_particles

def define_subregions(bed_length, num_subregions, iterations):
    &#34;&#34;&#34; Define subregion list for model stream.
    
    Args:
        bed_length: The length of the stream (int). 
        num_subregions: The number of subregions (int).
        iterations: The number of iterations for the model run (int).

    Returns:
        subregions_arr: Python array of initialized Subregion objects. 
    &#34;&#34;&#34;
    subregion_length = bed_length/num_subregions
    left_boundary = 0.0
    subregions_arr = []
    for region in range(num_subregions):  
        right_boundary = left_boundary + subregion_length   
        subregion = Subregion(f&#39;subregion-{region}&#39;, left_boundary, right_boundary, iterations)
        left_boundary = right_boundary
        
        subregions_arr.append(subregion)
    
    return subregions_arr
    
def build_streambed(bed_length, particle_diam):
    &#34;&#34;&#34; Builds the array of bed particles.
    
    Args:
        bed_length: The length of the stream (int).
        particle_diam: The diameter of all particles (float).
    
    Returns:
        bed_particles: An m-7 NumPy array representing the stream&#39;s m 
            bed particles. For example::

                [[x1, diam, y, uid1, active, age, loops], ... 
                            ,[xM, diam, y, uidM, active, age, loops]]
            
            Where all bed particles share the same diam (diam1=...=diamM) and 
            y (y1=...=yM), all uids are negative, and to represent &#39;static-ness&#39;
            active = 0, age = 0, and loops = 0. 

    &#34;&#34;&#34;
    max_particles = int(math.ceil( bed_length / particle_diam ))
    bed_particles = np.zeros([max_particles, 7],dtype=float)
    
    particle_id = -1
    centre = (particle_diam/2)  
    state = 0
    age = 0
    loop_age = 0
    elevation = 0
    while not bed_complete(centre, bed_length):  
        # index with negative indices... bed particles are built from the final element to the first
        bed_particles[particle_id] = [centre, particle_diam, elevation, particle_id, state, age, loop_age]
        centre += particle_diam
        particle_id += -1 # Bed particles get negative IDs
    
    return bed_particles

def bed_complete(centre, bed_length):
    if centre &gt;= bed_length:
        return 1
    else: return 0


def determine_num_particles(pack_frac, num_vertices):
    &#34;&#34;&#34;Return the number of model particles to be created
    based on the packing fraction&#34;&#34;&#34;
    
    num_particles = num_vertices * pack_frac
    num_particles = int(math.ceil(num_particles))
    
    return num_particles

# Trig from: https://math.stackexchange.com/questions/2293201/
def place_particle(particle, model_particles, bed_particles, h):
    &#34;&#34;&#34; Calculate new y (elevation) of particle based on it&#39;s 
        x (horizontal) location in stream.
    
    Provided a particle p&#39;s location x in the stream, 
    search for 2 supporting particles (s1, s2) that p 
    will rest on when placed at x.
    
    Calculate the y position of p based on the (x,y) of both 
    s1 and s2. The computed x for p might be different up to some 
    decimal point, so both x and y are rounded to 2 decimal places.

    
    Args:
        particle: NumPy array representing the model particle being placed.
        model_particles: An n-7 NumPy array representing the stream&#39;s n model particles.
        bed_particles: An m-7 NumPy array representing the stream&#39;s m bed particles.

    Returns:
        rounded_x: Rounded float of particle&#39;s new x location.
        rounded_y: Rounded float of particle&#39;s new y location.
        left_support: UID of the left support for the placed particle.
        right_support: UID of the right support for the placed particle.
    
    &#34;&#34;&#34;
    left_support, right_support = find_supports(particle, model_particles, bed_particles)
    rounded_x = round(particle[0], 2)
    rounded_y = round(np.add(h, left_support[2]), 2)
    return rounded_x, rounded_y, left_support[3], right_support[3]


def update_particle_states(model_particles, model_supports):
    &#34;&#34;&#34; Set/update each model particle&#39;s state. 
    
    If any model particle p has a particle 
    resting on it in the stream then p must 
    be set to inactive indicated by a boolean 0.
    
    If p does not have any particles resting
    on top of it then it is considered active 
    indicated by a boolean 1.
    
    Args:
        model_particles: An n-7 NumPy array representing the stream&#39;s 
            n model particles.
        model_supports: An n-2 NumPy array with the uids of the two 
            particles supporting each model particle.
        bed_particles: An m-7 NumPy array representing the stream&#39;s m bed
            particles.

    Return values:
        model_particles: The provided model_particles array (Args) 
            but with updated active (attribute 4) values.
    &#34;&#34;&#34;
    # Start by setting all model particles to active then 
    # only set to inactive if there is a particle sitting on top
    model_particles[:,4] = 1
    in_stream_particles = model_particles[model_particles[:,0] != -1]
    inactive_left = np.intersect1d(in_stream_particles[:,3], model_supports[:,0])
    inactive_right = np.intersect1d(in_stream_particles[:,3], model_supports[:,1])

    if inactive_left.size != 0:
        model_particles[inactive_left.astype(int), 4] = 0
    if inactive_right.size != 0:
        model_particles[inactive_right.astype(int), 4] = 0

    return model_particles


def find_supports(particle, model_particles, bed_particles):
    &#34;&#34;&#34; Find the 2 supporting particles for a given particle.

    Provided a particle p at location x, this function 
    will search the stream for particles that p would
    rest on, if being dropped at x. More generally, supporting particles 
    are those particles which directly hold up a particle. Supporting
    particles will always have a centre location that is 
    exactly a radius length away from p&#39;s centre.

    Args:
        particle: 1-7 NumPy array representing a model particle.
        model_particles: An n-7 NumPy array representing the stream&#39;s 
            n model particles.
        bed_particles: An m-7 NumPy array representing the stream&#39;s m 
            bed particles.

    Returns:
        left_support: NumPy array representing the left supporting particle
        right_support: NumPy array representing the right supporting particle
    &#34;&#34;&#34;  
    all_particles = np.concatenate((model_particles, bed_particles), axis=0)
    # Define location where left and right supporting particles must sit
    # in order to be considered a supporting particle.
    # Note: This limits the model to using same-sized grains.
    left_center = particle[0] - (particle[1] / 2)
    right_center = particle[0] + (particle[1] / 2)
     
    l_candidates = all_particles[all_particles[:,0] == left_center]
    try:
        left_support = l_candidates[l_candidates[:,2] 
                                    == np.max(l_candidates[:,2])]
    except ValueError:
        error_msg = (
                     f&#39;No left supporting particle at {left_center}&#39; 
                     f&#39;for particle {particle[3]}&#39;
        )
        logging.error(error_msg)
        raise   
        
    r_candidates = all_particles[all_particles[:,0] == right_center] 
    try:
        right_support = r_candidates[r_candidates[:,2] == np.max(r_candidates[:,2])]
    except ValueError:
        error_msg = (
                     f&#39;No right supporting particle at {right_center}&#39; 
                     f&#39;for particle {particle[3]}&#39;
        )
        logging.error(error_msg)
        raise
    return left_support[0], right_support[0]


def set_model_particles(bed_particles, available_vertices, particle_diam, pack_fraction, h):
    &#34;&#34;&#34; Create array of n model particles and set each particle in-stream.
    
    Model particles are randomly placed at available vertex
    locations (x,y) across the bed. Location and initial attribute
    values are stored in the returned NumPy array. 
    
    Args:
        bed_particles: An m-7 NumPy array representing the stream&#39;s m bed particles.
        available_vertices: A NumPy array with all available vertices in the stream. 
        particle_diam: The diameter of all particles (float).
        pack_fraction: Packing density value (float). See THEORY.md in project
            repo for more information.
        h: Geometric value used in calculations of particle placement (float). See
            in-line and project documentation for further explanation.
    
    Returns:
        model_particles: An n-7 NumPy array representing the stream&#39;s n model particles and their 
            initial placement in the stream. For example::
            
                [[x1, diam, y1, uid1, active, age, loops], ... ,[xN, diam, yN, uidN, active, age, loops]]

            Where (xi, yi) pairs will define the centre location of each particle and no two particles
            will have the same (xi, yi) pair values. All uids are unique and are positive whole numbers.
            All particles will start with active = 1, age = 0, and loops = 0.

        model_supp: An n-2 NumPy array with the uids of the two particles supporting each 
            model particle. For example::
        
                [[[-1,-2]], ... ,[-3,-4]]

            The above example states that model particle with uid 0 (model_supp[0]) is supported
            by bed particles with uids -1 and -2. Similarly, the model particle with uid n 
            (model_supp[n]) is supported by bed particles with uids -3 and -4. 
     &#34;&#34;&#34; 
    num_placement_loc = np.size(available_vertices)
    # determine the number of model particles that should be introduced into the stream bed
    num_particles = determine_num_particles(pack_fraction, num_placement_loc)
    # create an empty n-6 array to store model particle information
    model_particles = np.zeros([num_particles, 7], dtype=&#39;float&#39;)
    model_supp = np.zeros([num_particles, 2], dtype=&#39;float&#39;)
  
    for particle in range(num_particles):  
        # the following lines select a vertex to place the current particle at, 
        # and ensure that it is not already occupied by another particle
        random_idx = random.randint(0, np.size(available_vertices)-1)
        vertex = available_vertices[random_idx]
        available_vertices = available_vertices[available_vertices != vertex]

        # intialize the particle information
        model_particles[particle][0] = vertex 
        model_particles[particle][1] = particle_diam
        
        model_particles[particle][3] = particle # id number for each particle
        model_particles[particle][4] = 1 # each particle begins as active
        
        # place particle at the chosen vertex
        p_x, p_y, left_supp, right_supp  = place_particle(model_particles[particle], 
                                                            model_particles, 
                                                            bed_particles, 
                                                            h)
        model_particles[particle][0] = p_x
        model_particles[particle][2] = p_y
        model_particles[particle][5] = 0
        model_particles[particle][6] = 0

        model_supp[particle][0] = left_supp
        model_supp[particle][1] = right_supp
    
    return model_particles, model_supp


def compute_available_vertices(model_particles, bed_particles, particle_diam, level_limit,
                               lifted_particles=None):
    &#34;&#34;&#34; Compute the avaliable vertices in the model stream.

    An available vertex is an x location that a 
    model particle is able to be entrained to.
    This function identifies the distinct elevations 
    present in the stream then looks at subsets of 
    particles in decesnding order of their elevation,
    in order to compute available vertices.
    
    For each elevation group, if a particle is sitting on a vertex
    x, then x cannot be available (it is occupied) and it
    is considered nulled. Then vertices v created by two 
    particles touching are considered. If v is not already 
    nulled by a particle occupying the location at a higher
    level, then it is considered an available vertex. This ends once the bed 
    particles (the lowest elevation) have been considered.
    

    Args:
        model_particles: An n-7 NumPy array representing the stream&#39;s 
            n model particles.
        bed_particles: An m-7 NumPy array representing the stream&#39;s m 
            bed particles. 
        lifted_particles: UID of particles that are &#39;lifted&#39;. Lifted 
            particles will not be considered as present in the stream
            when the available vertices are being calculated; their
            (x,y) location will not be considered as occupied.
    
    Returns:
        available_vertices: A NumPy array with all available vertices in the stream. 
    &#34;&#34;&#34;
    nulled_vertices = []
    avail_vertices = []
    
    # If we are lifting particles, we need to consider the subset of particles
    # that includes every particles _except_ the particles being 
    if lifted_particles is not None:  
        model_particles_lifted = np.delete(model_particles, 
                                           lifted_particles, 0)
        all_particles = np.concatenate((model_particles_lifted, 
                                        bed_particles), axis=0)
    else:
        all_particles = np.concatenate((model_particles, 
                                        bed_particles), axis=0)
    # Get unique model particle elevations in stream (descending)
    elevations = elevation_list(all_particles[:,2])
    
    for idx, elevation in enumerate(elevations):
        tmp_particles = all_particles[all_particles[:,2] == elevation]
        
        for particle in tmp_particles:    
            nulled_vertices.append(particle[0])
        
        right_vertices = tmp_particles[:,0] + (particle_diam / 2)
        left_vertices = tmp_particles[:,0] - (particle_diam / 2)
        tmp_shared_vertices = np.intersect1d(left_vertices, right_vertices)
        
        # Enforce level limit by nulling any vertex above limit:
        if len(elevations) == level_limit+1 and idx==0: 
            for vertex in tmp_shared_vertices:
                nulled_vertices.append(vertex)
        
        for vertex in tmp_shared_vertices:
            if vertex not in nulled_vertices:
                avail_vertices.append(vertex)
                
        del(tmp_shared_vertices)
        del(tmp_particles)
        
    available_vertices = np.array(avail_vertices)
    
    return available_vertices


def elevation_list(elevations, desc=True):
    &#34;&#34;&#34; Returns a sorted list of unique elevation values &#34;&#34;&#34;
    ue = np.unique(elevations)
    if desc:
           ue = ue[::-1]
    return ue
 
def compute_hops(event_particle_ids, model_particles, mu, sigma, normal=False):
    &#34;&#34;&#34; Given a list of event paritcles, this function will 
    add a hop distance to current x locations of all event particles. 
    
    Current + Hop = desired hop distance. Hop values are randomly 
    selected from a log-normal or normal distribution. For more
    information on the use of these distributions see THEORY.md 
    in the project repository.
    
    Args:
        event_particle_ids: A NumPy array of k uids representing the model particles
            that have been selected for entrainment.
        model_particles: An n-7 NumPy array representing the stream&#39;s 
            n model particles.
        normal (default = False): Boolean flag for which distribution to sample
            Hop values from. True = sample from Normal, False = sample from log-Normal. 
    
    Returns:
        event_particles: A k-7 Numpy array representing each event particle
            with updated x locations (x=deried hop location).
    &#34;&#34;&#34;
    event_particles = model_particles[event_particle_ids]
    if normal:
        s = np.random.normal(mu, sigma, len(event_particle_ids))
    else:
        s = np.random.lognormal(mu, sigma, len(event_particle_ids))
    s_hop = np.round(s, 1)
    s_hop = list(s_hop)
    event_particles[:,0] = event_particles[:,0] + s_hop
    
    return event_particles
 
def move_model_particles(event_particles, model_particles, model_supp, bed_particles, available_vertices, h):
    &#34;&#34;&#34; Move model particles in the stream.
    
    Given an array of event particles and their desired hops, move each
    event particle in-stream based on the event particle&#39;s desired hop. Sometimes
    the desired hop will equal an available vertex and sometimes it will not.
    When it does not, move the particle to the closest vertex to the 
    desired hop in the downstream direction.

    Args:
        event_particles: A k-7 Numpy array representing event particle.
        model_particles: An n-7 NumPy array representing the stream&#39;s 
            n model particles.
        model_supp: An n-2 NumPy array with the uids of the two particles supporting each 
            model particle (e.g model_supp[j] = supports for model particle j).  
        bed_particles: An m-7 NumPy array representing the stream&#39;s m 
            bed particles. 
        available_vertices: A NumPy array with all available vertices in the stream. 
        h: Geometric value used in calculations of particle placement (float). See
            in-line and project documentation for further explanation.
    
    Returns:
        model_particles: The provided model_particles array (Args) 
            but with updated (x,y) attributes based on placements. 
        model_supports: An updated model_supports (Args) based on 
            placements. Note that only event particles will ever 
            have their model supports updated.
    &#34;&#34;&#34;
    # Randomly iterate over event particles
    for particle in np.random.permutation(event_particles):
        orig_x = model_particles[model_particles[:,3] == particle[3]][0][0]
        verified_hop = find_closest_vertex(particle[0], available_vertices)
        
        if verified_hop == -1:
            exceed_msg = (
                f&#39;Particle {int(particle[3])} exceeded stream...&#39;
                f&#39;sending to -1 axis&#39;
            )
            logging.info(exceed_msg) 
            particle[6] = particle[6] + 1
            particle[0] = verified_hop

            model_supp[int(particle[3])][0] = np.nan
            model_supp[int(particle[3])][1] = np.nan
        else:
            hop_msg = (
                f&#39;Particle {int(particle[3])} entrained from {orig_x} &#39;
                f&#39;to {verified_hop}. Desired hop was: {particle[0]}&#39;
            )
            logging.info(hop_msg)
            particle[0] = verified_hop
            available_vertices = available_vertices[available_vertices != verified_hop]

            placed_x, placed_y, left_supp, right_supp = place_particle(particle, model_particles, bed_particles, h)
            particle[0] = placed_x
            particle[2] = placed_y

            model_supp[int(particle[3])][0] = left_supp
            model_supp[int(particle[3])][1] = right_supp

        model_particles[model_particles[:,3] == particle[3]] = particle
    return model_particles, model_supp


def update_flux(initial_positions, final_positions, iteration, subregions):
    &#34;&#34;&#34; Update flux lists in each subregion.

    Given arrays of initial and final positions, this function 
    will update each subregion&#39;s flux list to indicate how many 
    paticles crossed the subregions&#39;s downstream boundary in 
    a given iteration.

    Args:
        initial_positions: NumPy array of initial x locations.
        final_positions: NumPy array of final (verified) x locations.
        iteration: The iteration for the flux to be updated for (int).
        subregions: Python array of Subregion objects.

    Returns:
        subregions: Python array of Subregion objects with updated flux lists.
    &#34;&#34;&#34;
    # This can _most definitely_ be made quicker but for now, it works
    if len(initial_positions) != len(final_positions):
        raise ValueError(f&#39;Initial_positions and final_positions do not contain the same # of elements&#39;)
    
    for position in range(0, len(initial_positions)):

        initial_pos = initial_positions[position]
        final_pos = final_positions[position]

        for idx, subregion in enumerate(subregions):
            if (initial_pos &gt;= subregion.leftBoundary()) and (subregion.rightBoundary() &gt; initial_pos):
                start_idx = idx

        for subregion_idx in range(start_idx, len(subregions)):
            if final_pos &gt;= subregions[subregion_idx].rightBoundary():
                subregions[subregion_idx].incrementFlux(iteration)
            elif final_pos == -1 and subregion_idx == len(subregions)-1:
                subregions[subregion_idx].incrementFlux(iteration)

    return subregions

    
def find_closest_vertex(desired_hop, available_vertices):
    &#34;&#34;&#34; Find the closest downstream (greater than or equal) vertex
    in availbale vertices. If nothing exists, return -1.
    
    Args:
        desired_hop: Float representing the desired hop location
        available_location: A NumPy array with all available vertices in the stream. 
    
    Returns:
        vertex: The location of the closest available vertex that 
            is &gt;= desired_hop (float).
    &#34;&#34;&#34;    
    if available_vertices.size == 0:
        raise ValueError(&#39;Available vertices array is empty, cannot find closest vertex&#39;)
    if desired_hop &lt; 0:
        raise ValueError(&#39;Desired hop is negative (invalid)&#39;)

    available_vertices = np.sort(available_vertices)
    forward_vertices = available_vertices[available_vertices &gt;= desired_hop]
    
    if forward_vertices.size &lt; 1:
        vertex = -1
    else:
        vertex = forward_vertices[0]
    return vertex    


def increment_age(model_particles, e_event_ids):
    &#34;&#34;&#34;Increment model particles&#39; age, set event particles to age 0&#34;&#34;&#34;
    
    model_particles[:,5] = model_particles[:,5] + 1 
    model_particles[e_event_ids, 5] = 0
    
    return model_particles</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="logic.bed_complete"><code class="name flex">
<span>def <span class="ident">bed_complete</span></span>(<span>centre, bed_length)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def bed_complete(centre, bed_length):
    if centre &gt;= bed_length:
        return 1
    else: return 0</code></pre>
</details>
</dd>
<dt id="logic.build_streambed"><code class="name flex">
<span>def <span class="ident">build_streambed</span></span>(<span>bed_length, particle_diam)</span>
</code></dt>
<dd>
<div class="desc"><p>Builds the array of bed particles.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>bed_length</code></strong></dt>
<dd>The length of the stream (int).</dd>
<dt><strong><code>particle_diam</code></strong></dt>
<dd>The diameter of all particles (float).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bed_particles</code></dt>
<dd>
<p>An m-7 NumPy array representing the stream's m
bed particles. For example::</p>
<pre><code>[[x1, diam, y, uid1, active, age, loops], ... 
            ,[xM, diam, y, uidM, active, age, loops]]
</code></pre>
<p>Where all bed particles share the same diam (diam1=&hellip;=diamM) and
y (y1=&hellip;=yM), all uids are negative, and to represent 'static-ness'
active = 0, age = 0, and loops = 0.</p>
</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build_streambed(bed_length, particle_diam):
    &#34;&#34;&#34; Builds the array of bed particles.
    
    Args:
        bed_length: The length of the stream (int).
        particle_diam: The diameter of all particles (float).
    
    Returns:
        bed_particles: An m-7 NumPy array representing the stream&#39;s m 
            bed particles. For example::

                [[x1, diam, y, uid1, active, age, loops], ... 
                            ,[xM, diam, y, uidM, active, age, loops]]
            
            Where all bed particles share the same diam (diam1=...=diamM) and 
            y (y1=...=yM), all uids are negative, and to represent &#39;static-ness&#39;
            active = 0, age = 0, and loops = 0. 

    &#34;&#34;&#34;
    max_particles = int(math.ceil( bed_length / particle_diam ))
    bed_particles = np.zeros([max_particles, 7],dtype=float)
    
    particle_id = -1
    centre = (particle_diam/2)  
    state = 0
    age = 0
    loop_age = 0
    elevation = 0
    while not bed_complete(centre, bed_length):  
        # index with negative indices... bed particles are built from the final element to the first
        bed_particles[particle_id] = [centre, particle_diam, elevation, particle_id, state, age, loop_age]
        centre += particle_diam
        particle_id += -1 # Bed particles get negative IDs
    
    return bed_particles</code></pre>
</details>
</dd>
<dt id="logic.compute_available_vertices"><code class="name flex">
<span>def <span class="ident">compute_available_vertices</span></span>(<span>model_particles, bed_particles, particle_diam, level_limit, lifted_particles=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the avaliable vertices in the model stream.</p>
<p>An available vertex is an x location that a
model particle is able to be entrained to.
This function identifies the distinct elevations
present in the stream then looks at subsets of
particles in decesnding order of their elevation,
in order to compute available vertices.</p>
<p>For each elevation group, if a particle is sitting on a vertex
x, then x cannot be available (it is occupied) and it
is considered nulled. Then vertices v created by two
particles touching are considered. If v is not already
nulled by a particle occupying the location at a higher
level, then it is considered an available vertex. This ends once the bed
particles (the lowest elevation) have been considered.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>model_particles</code></strong></dt>
<dd>An n-7 NumPy array representing the stream's
n model particles.</dd>
<dt><strong><code>bed_particles</code></strong></dt>
<dd>An m-7 NumPy array representing the stream's m
bed particles. </dd>
<dt><strong><code>lifted_particles</code></strong></dt>
<dd>UID of particles that are 'lifted'. Lifted
particles will not be considered as present in the stream
when the available vertices are being calculated; their
(x,y) location will not be considered as occupied.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>available_vertices</code></dt>
<dd>A NumPy array with all available vertices in the stream.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_available_vertices(model_particles, bed_particles, particle_diam, level_limit,
                               lifted_particles=None):
    &#34;&#34;&#34; Compute the avaliable vertices in the model stream.

    An available vertex is an x location that a 
    model particle is able to be entrained to.
    This function identifies the distinct elevations 
    present in the stream then looks at subsets of 
    particles in decesnding order of their elevation,
    in order to compute available vertices.
    
    For each elevation group, if a particle is sitting on a vertex
    x, then x cannot be available (it is occupied) and it
    is considered nulled. Then vertices v created by two 
    particles touching are considered. If v is not already 
    nulled by a particle occupying the location at a higher
    level, then it is considered an available vertex. This ends once the bed 
    particles (the lowest elevation) have been considered.
    

    Args:
        model_particles: An n-7 NumPy array representing the stream&#39;s 
            n model particles.
        bed_particles: An m-7 NumPy array representing the stream&#39;s m 
            bed particles. 
        lifted_particles: UID of particles that are &#39;lifted&#39;. Lifted 
            particles will not be considered as present in the stream
            when the available vertices are being calculated; their
            (x,y) location will not be considered as occupied.
    
    Returns:
        available_vertices: A NumPy array with all available vertices in the stream. 
    &#34;&#34;&#34;
    nulled_vertices = []
    avail_vertices = []
    
    # If we are lifting particles, we need to consider the subset of particles
    # that includes every particles _except_ the particles being 
    if lifted_particles is not None:  
        model_particles_lifted = np.delete(model_particles, 
                                           lifted_particles, 0)
        all_particles = np.concatenate((model_particles_lifted, 
                                        bed_particles), axis=0)
    else:
        all_particles = np.concatenate((model_particles, 
                                        bed_particles), axis=0)
    # Get unique model particle elevations in stream (descending)
    elevations = elevation_list(all_particles[:,2])
    
    for idx, elevation in enumerate(elevations):
        tmp_particles = all_particles[all_particles[:,2] == elevation]
        
        for particle in tmp_particles:    
            nulled_vertices.append(particle[0])
        
        right_vertices = tmp_particles[:,0] + (particle_diam / 2)
        left_vertices = tmp_particles[:,0] - (particle_diam / 2)
        tmp_shared_vertices = np.intersect1d(left_vertices, right_vertices)
        
        # Enforce level limit by nulling any vertex above limit:
        if len(elevations) == level_limit+1 and idx==0: 
            for vertex in tmp_shared_vertices:
                nulled_vertices.append(vertex)
        
        for vertex in tmp_shared_vertices:
            if vertex not in nulled_vertices:
                avail_vertices.append(vertex)
                
        del(tmp_shared_vertices)
        del(tmp_particles)
        
    available_vertices = np.array(avail_vertices)
    
    return available_vertices</code></pre>
</details>
</dd>
<dt id="logic.compute_hops"><code class="name flex">
<span>def <span class="ident">compute_hops</span></span>(<span>event_particle_ids, model_particles, mu, sigma, normal=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Given a list of event paritcles, this function will
add a hop distance to current x locations of all event particles. </p>
<p>Current + Hop = desired hop distance. Hop values are randomly
selected from a log-normal or normal distribution. For more
information on the use of these distributions see THEORY.md
in the project repository.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>event_particle_ids</code></strong></dt>
<dd>A NumPy array of k uids representing the model particles
that have been selected for entrainment.</dd>
<dt><strong><code>model_particles</code></strong></dt>
<dd>An n-7 NumPy array representing the stream's
n model particles.</dd>
<dt><strong><code>normal</code></strong> :&ensp;<code>default = False</code></dt>
<dd>Boolean flag for which distribution to sample
Hop values from. True = sample from Normal, False = sample from log-Normal. </dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>event_particles</code></dt>
<dd>A k-7 Numpy array representing each event particle
with updated x locations (x=deried hop location).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_hops(event_particle_ids, model_particles, mu, sigma, normal=False):
    &#34;&#34;&#34; Given a list of event paritcles, this function will 
    add a hop distance to current x locations of all event particles. 
    
    Current + Hop = desired hop distance. Hop values are randomly 
    selected from a log-normal or normal distribution. For more
    information on the use of these distributions see THEORY.md 
    in the project repository.
    
    Args:
        event_particle_ids: A NumPy array of k uids representing the model particles
            that have been selected for entrainment.
        model_particles: An n-7 NumPy array representing the stream&#39;s 
            n model particles.
        normal (default = False): Boolean flag for which distribution to sample
            Hop values from. True = sample from Normal, False = sample from log-Normal. 
    
    Returns:
        event_particles: A k-7 Numpy array representing each event particle
            with updated x locations (x=deried hop location).
    &#34;&#34;&#34;
    event_particles = model_particles[event_particle_ids]
    if normal:
        s = np.random.normal(mu, sigma, len(event_particle_ids))
    else:
        s = np.random.lognormal(mu, sigma, len(event_particle_ids))
    s_hop = np.round(s, 1)
    s_hop = list(s_hop)
    event_particles[:,0] = event_particles[:,0] + s_hop
    
    return event_particles</code></pre>
</details>
</dd>
<dt id="logic.define_subregions"><code class="name flex">
<span>def <span class="ident">define_subregions</span></span>(<span>bed_length, num_subregions, iterations)</span>
</code></dt>
<dd>
<div class="desc"><p>Define subregion list for model stream.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>bed_length</code></strong></dt>
<dd>The length of the stream (int). </dd>
<dt><strong><code>num_subregions</code></strong></dt>
<dd>The number of subregions (int).</dd>
<dt><strong><code>iterations</code></strong></dt>
<dd>The number of iterations for the model run (int).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>subregions_arr</code></dt>
<dd>Python array of initialized Subregion objects.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def define_subregions(bed_length, num_subregions, iterations):
    &#34;&#34;&#34; Define subregion list for model stream.
    
    Args:
        bed_length: The length of the stream (int). 
        num_subregions: The number of subregions (int).
        iterations: The number of iterations for the model run (int).

    Returns:
        subregions_arr: Python array of initialized Subregion objects. 
    &#34;&#34;&#34;
    subregion_length = bed_length/num_subregions
    left_boundary = 0.0
    subregions_arr = []
    for region in range(num_subregions):  
        right_boundary = left_boundary + subregion_length   
        subregion = Subregion(f&#39;subregion-{region}&#39;, left_boundary, right_boundary, iterations)
        left_boundary = right_boundary
        
        subregions_arr.append(subregion)
    
    return subregions_arr</code></pre>
</details>
</dd>
<dt id="logic.determine_num_particles"><code class="name flex">
<span>def <span class="ident">determine_num_particles</span></span>(<span>pack_frac, num_vertices)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the number of model particles to be created
based on the packing fraction</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def determine_num_particles(pack_frac, num_vertices):
    &#34;&#34;&#34;Return the number of model particles to be created
    based on the packing fraction&#34;&#34;&#34;
    
    num_particles = num_vertices * pack_frac
    num_particles = int(math.ceil(num_particles))
    
    return num_particles</code></pre>
</details>
</dd>
<dt id="logic.elevation_list"><code class="name flex">
<span>def <span class="ident">elevation_list</span></span>(<span>elevations, desc=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a sorted list of unique elevation values</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def elevation_list(elevations, desc=True):
    &#34;&#34;&#34; Returns a sorted list of unique elevation values &#34;&#34;&#34;
    ue = np.unique(elevations)
    if desc:
           ue = ue[::-1]
    return ue</code></pre>
</details>
</dd>
<dt id="logic.find_closest_vertex"><code class="name flex">
<span>def <span class="ident">find_closest_vertex</span></span>(<span>desired_hop, available_vertices)</span>
</code></dt>
<dd>
<div class="desc"><p>Find the closest downstream (greater than or equal) vertex
in availbale vertices. If nothing exists, return -1.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>desired_hop</code></strong></dt>
<dd>Float representing the desired hop location</dd>
<dt><strong><code>available_location</code></strong></dt>
<dd>A NumPy array with all available vertices in the stream. </dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>vertex</code></dt>
<dd>The location of the closest available vertex that
is &gt;= desired_hop (float).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_closest_vertex(desired_hop, available_vertices):
    &#34;&#34;&#34; Find the closest downstream (greater than or equal) vertex
    in availbale vertices. If nothing exists, return -1.
    
    Args:
        desired_hop: Float representing the desired hop location
        available_location: A NumPy array with all available vertices in the stream. 
    
    Returns:
        vertex: The location of the closest available vertex that 
            is &gt;= desired_hop (float).
    &#34;&#34;&#34;    
    if available_vertices.size == 0:
        raise ValueError(&#39;Available vertices array is empty, cannot find closest vertex&#39;)
    if desired_hop &lt; 0:
        raise ValueError(&#39;Desired hop is negative (invalid)&#39;)

    available_vertices = np.sort(available_vertices)
    forward_vertices = available_vertices[available_vertices &gt;= desired_hop]
    
    if forward_vertices.size &lt; 1:
        vertex = -1
    else:
        vertex = forward_vertices[0]
    return vertex    </code></pre>
</details>
</dd>
<dt id="logic.find_supports"><code class="name flex">
<span>def <span class="ident">find_supports</span></span>(<span>particle, model_particles, bed_particles)</span>
</code></dt>
<dd>
<div class="desc"><p>Find the 2 supporting particles for a given particle.</p>
<p>Provided a particle p at location x, this function
will search the stream for particles that p would
rest on, if being dropped at x. More generally, supporting particles
are those particles which directly hold up a particle. Supporting
particles will always have a centre location that is
exactly a radius length away from p's centre.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>particle</code></strong></dt>
<dd>1-7 NumPy array representing a model particle.</dd>
<dt><strong><code>model_particles</code></strong></dt>
<dd>An n-7 NumPy array representing the stream's
n model particles.</dd>
<dt><strong><code>bed_particles</code></strong></dt>
<dd>An m-7 NumPy array representing the stream's m
bed particles.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>left_support</code></dt>
<dd>NumPy array representing the left supporting particle</dd>
<dt><code>right_support</code></dt>
<dd>NumPy array representing the right supporting particle</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_supports(particle, model_particles, bed_particles):
    &#34;&#34;&#34; Find the 2 supporting particles for a given particle.

    Provided a particle p at location x, this function 
    will search the stream for particles that p would
    rest on, if being dropped at x. More generally, supporting particles 
    are those particles which directly hold up a particle. Supporting
    particles will always have a centre location that is 
    exactly a radius length away from p&#39;s centre.

    Args:
        particle: 1-7 NumPy array representing a model particle.
        model_particles: An n-7 NumPy array representing the stream&#39;s 
            n model particles.
        bed_particles: An m-7 NumPy array representing the stream&#39;s m 
            bed particles.

    Returns:
        left_support: NumPy array representing the left supporting particle
        right_support: NumPy array representing the right supporting particle
    &#34;&#34;&#34;  
    all_particles = np.concatenate((model_particles, bed_particles), axis=0)
    # Define location where left and right supporting particles must sit
    # in order to be considered a supporting particle.
    # Note: This limits the model to using same-sized grains.
    left_center = particle[0] - (particle[1] / 2)
    right_center = particle[0] + (particle[1] / 2)
     
    l_candidates = all_particles[all_particles[:,0] == left_center]
    try:
        left_support = l_candidates[l_candidates[:,2] 
                                    == np.max(l_candidates[:,2])]
    except ValueError:
        error_msg = (
                     f&#39;No left supporting particle at {left_center}&#39; 
                     f&#39;for particle {particle[3]}&#39;
        )
        logging.error(error_msg)
        raise   
        
    r_candidates = all_particles[all_particles[:,0] == right_center] 
    try:
        right_support = r_candidates[r_candidates[:,2] == np.max(r_candidates[:,2])]
    except ValueError:
        error_msg = (
                     f&#39;No right supporting particle at {right_center}&#39; 
                     f&#39;for particle {particle[3]}&#39;
        )
        logging.error(error_msg)
        raise
    return left_support[0], right_support[0]</code></pre>
</details>
</dd>
<dt id="logic.get_event_particles"><code class="name flex">
<span>def <span class="ident">get_event_particles</span></span>(<span>e_events, subregions, model_particles, level_limit, height_dependant=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Find and return list of particles to be entrained</p>
<p>Will loop through each subregion and select n = e_events
model particles (within a subregion boundaries) at random
to be entrained. No particle will be selected twice.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>e_events</code></strong></dt>
<dd>The number of events requested per subregion (int).</dd>
<dt><strong><code>subregions</code></strong></dt>
<dd>Python array of initialized Subregion objects. </dd>
<dt><strong><code>model_particles</code></strong></dt>
<dd>An n-7 NumPy array representing the stream's n
model particles.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>event_particles</code></dt>
<dd>
<p>A NumPy array of k uids representing the model particles
that have been selected for entrainment. For example::</p>
<pre><code>[2.0, 5.0, 25.0]
</code></pre>
<p>Will represent that model particles with uids 2.0, 5.0 and
25.0 have been selected for entrainment.</p>
</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_event_particles(e_events, subregions, model_particles, level_limit, height_dependant=False):
    &#34;&#34;&#34; Find and return list of particles to be entrained

    Will loop through each subregion and select n = e_events
    model particles (within a subregion boundaries) at random 
    to be entrained. No particle will be selected twice.

    Args:
        e_events: The number of events requested per subregion (int).
        subregions: Python array of initialized Subregion objects. 
        model_particles: An n-7 NumPy array representing the stream&#39;s n 
            model particles.

    Returns:
        event_particles: A NumPy array of k uids representing the model particles
            that have been selected for entrainment. For example::

                [2.0, 5.0, 25.0]

            Will represent that model particles with uids 2.0, 5.0 and
            25.0 have been selected for entrainment. 
    &#34;&#34;&#34;
    if e_events == 0:
        e_events = 1 #???
    
    event_particles = []
    for subregion in subregions:
        # Take only particles in the boundaries of the current subregion
        subregion_particles = model_particles[
                (model_particles[:,0] &gt;= subregion.leftBoundary())
              &amp; (model_particles[:,0] &lt;= subregion.rightBoundary())]
        # Take only particles that are in-stream (not ghost)
        in_stream_particles = subregion_particles[
                                                subregion_particles[:,0] != -1]
        # Take only particles that are &#39;active&#39; 
        active_particles =  in_stream_particles[
                                                in_stream_particles[:,4] != 0]

        # Do not take any particles that have been selected for entrainment (i.e do not double select)
        # This only happens when particles rest on the boundary. 
        active_event, active_idx, event_idx = np.intersect1d(active_particles[:,3], event_particles, return_indices=True)
        active_particles = np.delete(active_particles, active_idx, axis=0)

        subregion_event_ids = []  
        if height_dependant: # any particle at the level limit must be entrained
            levels = elevation_list(subregion_particles[:,2], desc=False)
            tip_particles = []
            # find the tip particles -- these are the particles being entrained
            if len(levels) == level_limit: 
                tip_particles = active_particles[active_particles[:,2] == levels[level_limit-1]]
            for particle in tip_particles:
                subregion_event_ids.append(particle[3])
                active_particles = active_particles[active_particles[:,2] != particle[2]]
        # If there are not enough particles in the subregion to sample from, alter the sample size
        if e_events &gt; len(active_particles):
            random_sample = random.sample(range(len(active_particles)), 
                                        len(active_particles))
        else: 
            random_sample = random.sample(range(len(active_particles)), 
                                        e_events)
        # TODO: change so that we don&#39;t rely on loop index to grab particle
        for index in random_sample:
            subregion_event_ids.append(int(active_particles[index][3])  )
        
        ghost_particles = np.where(model_particles[:,0] == -1)[0]
        for index in ghost_particles:
            model_particles[index][0] = 0 
            subregion_event_ids.append(index)
        
        if e_events != len(subregion_event_ids):
            msg = (
                     f&#39;Requested {e_events} events in {subregion.getName()} &#39; 
                     f&#39;but {len(subregion_event_ids)} are occuring&#39;
            )
            logging.info(msg)
        event_particles = event_particles + subregion_event_ids
    event_particles = np.array(event_particles, dtype=np.intp)

    return event_particles</code></pre>
</details>
</dd>
<dt id="logic.increment_age"><code class="name flex">
<span>def <span class="ident">increment_age</span></span>(<span>model_particles, e_event_ids)</span>
</code></dt>
<dd>
<div class="desc"><p>Increment model particles' age, set event particles to age 0</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def increment_age(model_particles, e_event_ids):
    &#34;&#34;&#34;Increment model particles&#39; age, set event particles to age 0&#34;&#34;&#34;
    
    model_particles[:,5] = model_particles[:,5] + 1 
    model_particles[e_event_ids, 5] = 0
    
    return model_particles</code></pre>
</details>
</dd>
<dt id="logic.move_model_particles"><code class="name flex">
<span>def <span class="ident">move_model_particles</span></span>(<span>event_particles, model_particles, model_supp, bed_particles, available_vertices, h)</span>
</code></dt>
<dd>
<div class="desc"><p>Move model particles in the stream.</p>
<p>Given an array of event particles and their desired hops, move each
event particle in-stream based on the event particle's desired hop. Sometimes
the desired hop will equal an available vertex and sometimes it will not.
When it does not, move the particle to the closest vertex to the
desired hop in the downstream direction.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>event_particles</code></strong></dt>
<dd>A k-7 Numpy array representing event particle.</dd>
<dt><strong><code>model_particles</code></strong></dt>
<dd>An n-7 NumPy array representing the stream's
n model particles.</dd>
<dt><strong><code>model_supp</code></strong></dt>
<dd>An n-2 NumPy array with the uids of the two particles supporting each
model particle (e.g model_supp[j] = supports for model particle j).
</dd>
<dt><strong><code>bed_particles</code></strong></dt>
<dd>An m-7 NumPy array representing the stream's m
bed particles. </dd>
<dt><strong><code>available_vertices</code></strong></dt>
<dd>A NumPy array with all available vertices in the stream. </dd>
<dt><strong><code>h</code></strong></dt>
<dd>Geometric value used in calculations of particle placement (float). See
in-line and project documentation for further explanation.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>model_particles</code></dt>
<dd>The provided model_particles array (Args)
but with updated (x,y) attributes based on placements. </dd>
<dt><code>model_supports</code></dt>
<dd>An updated model_supports (Args) based on
placements. Note that only event particles will ever
have their model supports updated.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def move_model_particles(event_particles, model_particles, model_supp, bed_particles, available_vertices, h):
    &#34;&#34;&#34; Move model particles in the stream.
    
    Given an array of event particles and their desired hops, move each
    event particle in-stream based on the event particle&#39;s desired hop. Sometimes
    the desired hop will equal an available vertex and sometimes it will not.
    When it does not, move the particle to the closest vertex to the 
    desired hop in the downstream direction.

    Args:
        event_particles: A k-7 Numpy array representing event particle.
        model_particles: An n-7 NumPy array representing the stream&#39;s 
            n model particles.
        model_supp: An n-2 NumPy array with the uids of the two particles supporting each 
            model particle (e.g model_supp[j] = supports for model particle j).  
        bed_particles: An m-7 NumPy array representing the stream&#39;s m 
            bed particles. 
        available_vertices: A NumPy array with all available vertices in the stream. 
        h: Geometric value used in calculations of particle placement (float). See
            in-line and project documentation for further explanation.
    
    Returns:
        model_particles: The provided model_particles array (Args) 
            but with updated (x,y) attributes based on placements. 
        model_supports: An updated model_supports (Args) based on 
            placements. Note that only event particles will ever 
            have their model supports updated.
    &#34;&#34;&#34;
    # Randomly iterate over event particles
    for particle in np.random.permutation(event_particles):
        orig_x = model_particles[model_particles[:,3] == particle[3]][0][0]
        verified_hop = find_closest_vertex(particle[0], available_vertices)
        
        if verified_hop == -1:
            exceed_msg = (
                f&#39;Particle {int(particle[3])} exceeded stream...&#39;
                f&#39;sending to -1 axis&#39;
            )
            logging.info(exceed_msg) 
            particle[6] = particle[6] + 1
            particle[0] = verified_hop

            model_supp[int(particle[3])][0] = np.nan
            model_supp[int(particle[3])][1] = np.nan
        else:
            hop_msg = (
                f&#39;Particle {int(particle[3])} entrained from {orig_x} &#39;
                f&#39;to {verified_hop}. Desired hop was: {particle[0]}&#39;
            )
            logging.info(hop_msg)
            particle[0] = verified_hop
            available_vertices = available_vertices[available_vertices != verified_hop]

            placed_x, placed_y, left_supp, right_supp = place_particle(particle, model_particles, bed_particles, h)
            particle[0] = placed_x
            particle[2] = placed_y

            model_supp[int(particle[3])][0] = left_supp
            model_supp[int(particle[3])][1] = right_supp

        model_particles[model_particles[:,3] == particle[3]] = particle
    return model_particles, model_supp</code></pre>
</details>
</dd>
<dt id="logic.place_particle"><code class="name flex">
<span>def <span class="ident">place_particle</span></span>(<span>particle, model_particles, bed_particles, h)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate new y (elevation) of particle based on it's
x (horizontal) location in stream.</p>
<p>Provided a particle p's location x in the stream,
search for 2 supporting particles (s1, s2) that p
will rest on when placed at x.</p>
<p>Calculate the y position of p based on the (x,y) of both
s1 and s2. The computed x for p might be different up to some
decimal point, so both x and y are rounded to 2 decimal places.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>particle</code></strong></dt>
<dd>NumPy array representing the model particle being placed.</dd>
<dt><strong><code>model_particles</code></strong></dt>
<dd>An n-7 NumPy array representing the stream's n model particles.</dd>
<dt><strong><code>bed_particles</code></strong></dt>
<dd>An m-7 NumPy array representing the stream's m bed particles.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>rounded_x</code></dt>
<dd>Rounded float of particle's new x location.</dd>
<dt><code>rounded_y</code></dt>
<dd>Rounded float of particle's new y location.</dd>
<dt><code>left_support</code></dt>
<dd>UID of the left support for the placed particle.</dd>
<dt><code>right_support</code></dt>
<dd>UID of the right support for the placed particle.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def place_particle(particle, model_particles, bed_particles, h):
    &#34;&#34;&#34; Calculate new y (elevation) of particle based on it&#39;s 
        x (horizontal) location in stream.
    
    Provided a particle p&#39;s location x in the stream, 
    search for 2 supporting particles (s1, s2) that p 
    will rest on when placed at x.
    
    Calculate the y position of p based on the (x,y) of both 
    s1 and s2. The computed x for p might be different up to some 
    decimal point, so both x and y are rounded to 2 decimal places.

    
    Args:
        particle: NumPy array representing the model particle being placed.
        model_particles: An n-7 NumPy array representing the stream&#39;s n model particles.
        bed_particles: An m-7 NumPy array representing the stream&#39;s m bed particles.

    Returns:
        rounded_x: Rounded float of particle&#39;s new x location.
        rounded_y: Rounded float of particle&#39;s new y location.
        left_support: UID of the left support for the placed particle.
        right_support: UID of the right support for the placed particle.
    
    &#34;&#34;&#34;
    left_support, right_support = find_supports(particle, model_particles, bed_particles)
    rounded_x = round(particle[0], 2)
    rounded_y = round(np.add(h, left_support[2]), 2)
    return rounded_x, rounded_y, left_support[3], right_support[3]</code></pre>
</details>
</dd>
<dt id="logic.set_model_particles"><code class="name flex">
<span>def <span class="ident">set_model_particles</span></span>(<span>bed_particles, available_vertices, particle_diam, pack_fraction, h)</span>
</code></dt>
<dd>
<div class="desc"><p>Create array of n model particles and set each particle in-stream.</p>
<p>Model particles are randomly placed at available vertex
locations (x,y) across the bed. Location and initial attribute
values are stored in the returned NumPy array. </p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>bed_particles</code></strong></dt>
<dd>An m-7 NumPy array representing the stream's m bed particles.</dd>
<dt><strong><code>available_vertices</code></strong></dt>
<dd>A NumPy array with all available vertices in the stream. </dd>
<dt><strong><code>particle_diam</code></strong></dt>
<dd>The diameter of all particles (float).</dd>
<dt><strong><code>pack_fraction</code></strong></dt>
<dd>Packing density value (float). See THEORY.md in project
repo for more information.</dd>
<dt><strong><code>h</code></strong></dt>
<dd>Geometric value used in calculations of particle placement (float). See
in-line and project documentation for further explanation.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>model_particles</code></dt>
<dd>
<p>An n-7 NumPy array representing the stream's n model particles and their
initial placement in the stream. For example::</p>
<pre><code>[[x1, diam, y1, uid1, active, age, loops], ... ,[xN, diam, yN, uidN, active, age, loops]]
</code></pre>
<p>Where (xi, yi) pairs will define the centre location of each particle and no two particles
will have the same (xi, yi) pair values. All uids are unique and are positive whole numbers.
All particles will start with active = 1, age = 0, and loops = 0.</p>
</dd>
<dt><code>model_supp</code></dt>
<dd>
<p>An n-2 NumPy array with the uids of the two particles supporting each
model particle. For example::</p>
<pre><code>[[[-1,-2]], ... ,[-3,-4]]
</code></pre>
<p>The above example states that model particle with uid 0 (model_supp[0]) is supported
by bed particles with uids -1 and -2. Similarly, the model particle with uid n
(model_supp[n]) is supported by bed particles with uids -3 and -4.</p>
</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_model_particles(bed_particles, available_vertices, particle_diam, pack_fraction, h):
    &#34;&#34;&#34; Create array of n model particles and set each particle in-stream.
    
    Model particles are randomly placed at available vertex
    locations (x,y) across the bed. Location and initial attribute
    values are stored in the returned NumPy array. 
    
    Args:
        bed_particles: An m-7 NumPy array representing the stream&#39;s m bed particles.
        available_vertices: A NumPy array with all available vertices in the stream. 
        particle_diam: The diameter of all particles (float).
        pack_fraction: Packing density value (float). See THEORY.md in project
            repo for more information.
        h: Geometric value used in calculations of particle placement (float). See
            in-line and project documentation for further explanation.
    
    Returns:
        model_particles: An n-7 NumPy array representing the stream&#39;s n model particles and their 
            initial placement in the stream. For example::
            
                [[x1, diam, y1, uid1, active, age, loops], ... ,[xN, diam, yN, uidN, active, age, loops]]

            Where (xi, yi) pairs will define the centre location of each particle and no two particles
            will have the same (xi, yi) pair values. All uids are unique and are positive whole numbers.
            All particles will start with active = 1, age = 0, and loops = 0.

        model_supp: An n-2 NumPy array with the uids of the two particles supporting each 
            model particle. For example::
        
                [[[-1,-2]], ... ,[-3,-4]]

            The above example states that model particle with uid 0 (model_supp[0]) is supported
            by bed particles with uids -1 and -2. Similarly, the model particle with uid n 
            (model_supp[n]) is supported by bed particles with uids -3 and -4. 
     &#34;&#34;&#34; 
    num_placement_loc = np.size(available_vertices)
    # determine the number of model particles that should be introduced into the stream bed
    num_particles = determine_num_particles(pack_fraction, num_placement_loc)
    # create an empty n-6 array to store model particle information
    model_particles = np.zeros([num_particles, 7], dtype=&#39;float&#39;)
    model_supp = np.zeros([num_particles, 2], dtype=&#39;float&#39;)
  
    for particle in range(num_particles):  
        # the following lines select a vertex to place the current particle at, 
        # and ensure that it is not already occupied by another particle
        random_idx = random.randint(0, np.size(available_vertices)-1)
        vertex = available_vertices[random_idx]
        available_vertices = available_vertices[available_vertices != vertex]

        # intialize the particle information
        model_particles[particle][0] = vertex 
        model_particles[particle][1] = particle_diam
        
        model_particles[particle][3] = particle # id number for each particle
        model_particles[particle][4] = 1 # each particle begins as active
        
        # place particle at the chosen vertex
        p_x, p_y, left_supp, right_supp  = place_particle(model_particles[particle], 
                                                            model_particles, 
                                                            bed_particles, 
                                                            h)
        model_particles[particle][0] = p_x
        model_particles[particle][2] = p_y
        model_particles[particle][5] = 0
        model_particles[particle][6] = 0

        model_supp[particle][0] = left_supp
        model_supp[particle][1] = right_supp
    
    return model_particles, model_supp</code></pre>
</details>
</dd>
<dt id="logic.update_flux"><code class="name flex">
<span>def <span class="ident">update_flux</span></span>(<span>initial_positions, final_positions, iteration, subregions)</span>
</code></dt>
<dd>
<div class="desc"><p>Update flux lists in each subregion.</p>
<p>Given arrays of initial and final positions, this function
will update each subregion's flux list to indicate how many
paticles crossed the subregions's downstream boundary in
a given iteration.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>initial_positions</code></strong></dt>
<dd>NumPy array of initial x locations.</dd>
<dt><strong><code>final_positions</code></strong></dt>
<dd>NumPy array of final (verified) x locations.</dd>
<dt><strong><code>iteration</code></strong></dt>
<dd>The iteration for the flux to be updated for (int).</dd>
<dt><strong><code>subregions</code></strong></dt>
<dd>Python array of Subregion objects.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>subregions</code></dt>
<dd>Python array of Subregion objects with updated flux lists.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_flux(initial_positions, final_positions, iteration, subregions):
    &#34;&#34;&#34; Update flux lists in each subregion.

    Given arrays of initial and final positions, this function 
    will update each subregion&#39;s flux list to indicate how many 
    paticles crossed the subregions&#39;s downstream boundary in 
    a given iteration.

    Args:
        initial_positions: NumPy array of initial x locations.
        final_positions: NumPy array of final (verified) x locations.
        iteration: The iteration for the flux to be updated for (int).
        subregions: Python array of Subregion objects.

    Returns:
        subregions: Python array of Subregion objects with updated flux lists.
    &#34;&#34;&#34;
    # This can _most definitely_ be made quicker but for now, it works
    if len(initial_positions) != len(final_positions):
        raise ValueError(f&#39;Initial_positions and final_positions do not contain the same # of elements&#39;)
    
    for position in range(0, len(initial_positions)):

        initial_pos = initial_positions[position]
        final_pos = final_positions[position]

        for idx, subregion in enumerate(subregions):
            if (initial_pos &gt;= subregion.leftBoundary()) and (subregion.rightBoundary() &gt; initial_pos):
                start_idx = idx

        for subregion_idx in range(start_idx, len(subregions)):
            if final_pos &gt;= subregions[subregion_idx].rightBoundary():
                subregions[subregion_idx].incrementFlux(iteration)
            elif final_pos == -1 and subregion_idx == len(subregions)-1:
                subregions[subregion_idx].incrementFlux(iteration)

    return subregions</code></pre>
</details>
</dd>
<dt id="logic.update_particle_states"><code class="name flex">
<span>def <span class="ident">update_particle_states</span></span>(<span>model_particles, model_supports)</span>
</code></dt>
<dd>
<div class="desc"><p>Set/update each model particle's state. </p>
<p>If any model particle p has a particle
resting on it in the stream then p must
be set to inactive indicated by a boolean 0.</p>
<p>If p does not have any particles resting
on top of it then it is considered active
indicated by a boolean 1.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>model_particles</code></strong></dt>
<dd>An n-7 NumPy array representing the stream's
n model particles.</dd>
<dt><strong><code>model_supports</code></strong></dt>
<dd>An n-2 NumPy array with the uids of the two
particles supporting each model particle.</dd>
<dt><strong><code>bed_particles</code></strong></dt>
<dd>An m-7 NumPy array representing the stream's m bed
particles.</dd>
</dl>
<p>Return values:
model_particles: The provided model_particles array (Args)
but with updated active (attribute 4) values.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_particle_states(model_particles, model_supports):
    &#34;&#34;&#34; Set/update each model particle&#39;s state. 
    
    If any model particle p has a particle 
    resting on it in the stream then p must 
    be set to inactive indicated by a boolean 0.
    
    If p does not have any particles resting
    on top of it then it is considered active 
    indicated by a boolean 1.
    
    Args:
        model_particles: An n-7 NumPy array representing the stream&#39;s 
            n model particles.
        model_supports: An n-2 NumPy array with the uids of the two 
            particles supporting each model particle.
        bed_particles: An m-7 NumPy array representing the stream&#39;s m bed
            particles.

    Return values:
        model_particles: The provided model_particles array (Args) 
            but with updated active (attribute 4) values.
    &#34;&#34;&#34;
    # Start by setting all model particles to active then 
    # only set to inactive if there is a particle sitting on top
    model_particles[:,4] = 1
    in_stream_particles = model_particles[model_particles[:,0] != -1]
    inactive_left = np.intersect1d(in_stream_particles[:,3], model_supports[:,0])
    inactive_right = np.intersect1d(in_stream_particles[:,3], model_supports[:,1])

    if inactive_left.size != 0:
        model_particles[inactive_left.astype(int), 4] = 0
    if inactive_right.size != 0:
        model_particles[inactive_right.astype(int), 4] = 0

    return model_particles</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="logic.Subregion"><code class="flex name class">
<span>class <span class="ident">Subregion</span></span>
<span>(</span><span>name, left_boundary, right_boundary, iterations)</span>
</code></dt>
<dd>
<div class="desc"><p>A subregion in the stream.</p>
<p>A Subregion is defined by left (upstream)
and right (downstream) boundaries. Each
subregion maintains a NumPy list which is
used to record the number of model particles that
pass the downstream boundary in a given iteration.
For example::</p>
<pre><code>flux_list = [0,3,2,1]
</code></pre>
<p>Means that 0 crossings happened in the first iteration,
3 happened in the 2nd, and so on. The list has
length equal to the number of iterations for a model run.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>name</code></strong></dt>
<dd>Name of the subregion.</dd>
<dt><strong><code>left_boundary</code></strong></dt>
<dd>Location of the left boundary (float).</dd>
<dt><strong><code>right_boundary</code></strong></dt>
<dd>Location of the right boundary (float).</dd>
<dt><strong><code>iterations</code></strong></dt>
<dd>The number of iterations for the model run.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Subregion():
    &#34;&#34;&#34; A subregion in the stream.
    
    A Subregion is defined by left (upstream)
    and right (downstream) boundaries. Each
    subregion maintains a NumPy list which is 
    used to record the number of model particles that 
    pass the downstream boundary in a given iteration. 
    For example::

        flux_list = [0,3,2,1]

    Means that 0 crossings happened in the first iteration, 
    3 happened in the 2nd, and so on. The list has 
    length equal to the number of iterations for a model run.
    
    Attributes:
        name: Name of the subregion.
        left_boundary: Location of the left boundary (float).
        right_boundary: Location of the right boundary (float).
        iterations: The number of iterations for the model run.
    &#34;&#34;&#34;
    def __init__(self, name, left_boundary, right_boundary, iterations):
        self.name = name
        self.left_boundary = left_boundary
        self.right_boundary = right_boundary
        self.flux_list = np.zeros(iterations, dtype=np.int64)
        
    def leftBoundary(self):
        &#34;&#34;&#34;Returns subregion&#39;s left boundary&#34;&#34;&#34;
        return self.left_boundary
    
    def rightBoundary(self):
        &#34;&#34;&#34;Returns subregion&#39;s right boundary&#34;&#34;&#34;
        return self.right_boundary
    
    def getName(self):
        &#34;&#34;&#34;Returns subregion&#39;s name&#34;&#34;&#34;
        return self.name

    def incrementFlux(self, iteration):
        &#34;&#34;&#34;Increments flux list by 1.

        Args:
            iteration: The iteration/index to increment by 1
        &#34;&#34;&#34;
        self.flux_list[iteration] += 1
    
    def getFluxList(self):
        &#34;&#34;&#34;Returns subregion&#39;s flux list&#34;&#34;&#34;
        return self.flux_list</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="logic.Subregion.getFluxList"><code class="name flex">
<span>def <span class="ident">getFluxList</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns subregion's flux list</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getFluxList(self):
    &#34;&#34;&#34;Returns subregion&#39;s flux list&#34;&#34;&#34;
    return self.flux_list</code></pre>
</details>
</dd>
<dt id="logic.Subregion.getName"><code class="name flex">
<span>def <span class="ident">getName</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns subregion's name</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getName(self):
    &#34;&#34;&#34;Returns subregion&#39;s name&#34;&#34;&#34;
    return self.name</code></pre>
</details>
</dd>
<dt id="logic.Subregion.incrementFlux"><code class="name flex">
<span>def <span class="ident">incrementFlux</span></span>(<span>self, iteration)</span>
</code></dt>
<dd>
<div class="desc"><p>Increments flux list by 1.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>iteration</code></strong></dt>
<dd>The iteration/index to increment by 1</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def incrementFlux(self, iteration):
    &#34;&#34;&#34;Increments flux list by 1.

    Args:
        iteration: The iteration/index to increment by 1
    &#34;&#34;&#34;
    self.flux_list[iteration] += 1</code></pre>
</details>
</dd>
<dt id="logic.Subregion.leftBoundary"><code class="name flex">
<span>def <span class="ident">leftBoundary</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns subregion's left boundary</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def leftBoundary(self):
    &#34;&#34;&#34;Returns subregion&#39;s left boundary&#34;&#34;&#34;
    return self.left_boundary</code></pre>
</details>
</dd>
<dt id="logic.Subregion.rightBoundary"><code class="name flex">
<span>def <span class="ident">rightBoundary</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns subregion's right boundary</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rightBoundary(self):
    &#34;&#34;&#34;Returns subregion&#39;s right boundary&#34;&#34;&#34;
    return self.right_boundary</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="logic.bed_complete" href="#logic.bed_complete">bed_complete</a></code></li>
<li><code><a title="logic.build_streambed" href="#logic.build_streambed">build_streambed</a></code></li>
<li><code><a title="logic.compute_available_vertices" href="#logic.compute_available_vertices">compute_available_vertices</a></code></li>
<li><code><a title="logic.compute_hops" href="#logic.compute_hops">compute_hops</a></code></li>
<li><code><a title="logic.define_subregions" href="#logic.define_subregions">define_subregions</a></code></li>
<li><code><a title="logic.determine_num_particles" href="#logic.determine_num_particles">determine_num_particles</a></code></li>
<li><code><a title="logic.elevation_list" href="#logic.elevation_list">elevation_list</a></code></li>
<li><code><a title="logic.find_closest_vertex" href="#logic.find_closest_vertex">find_closest_vertex</a></code></li>
<li><code><a title="logic.find_supports" href="#logic.find_supports">find_supports</a></code></li>
<li><code><a title="logic.get_event_particles" href="#logic.get_event_particles">get_event_particles</a></code></li>
<li><code><a title="logic.increment_age" href="#logic.increment_age">increment_age</a></code></li>
<li><code><a title="logic.move_model_particles" href="#logic.move_model_particles">move_model_particles</a></code></li>
<li><code><a title="logic.place_particle" href="#logic.place_particle">place_particle</a></code></li>
<li><code><a title="logic.set_model_particles" href="#logic.set_model_particles">set_model_particles</a></code></li>
<li><code><a title="logic.update_flux" href="#logic.update_flux">update_flux</a></code></li>
<li><code><a title="logic.update_particle_states" href="#logic.update_particle_states">update_particle_states</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="logic.Subregion" href="#logic.Subregion">Subregion</a></code></h4>
<ul class="">
<li><code><a title="logic.Subregion.getFluxList" href="#logic.Subregion.getFluxList">getFluxList</a></code></li>
<li><code><a title="logic.Subregion.getName" href="#logic.Subregion.getName">getName</a></code></li>
<li><code><a title="logic.Subregion.incrementFlux" href="#logic.Subregion.incrementFlux">incrementFlux</a></code></li>
<li><code><a title="logic.Subregion.leftBoundary" href="#logic.Subregion.leftBoundary">leftBoundary</a></code></li>
<li><code><a title="logic.Subregion.rightBoundary" href="#logic.Subregion.rightBoundary">rightBoundary</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>
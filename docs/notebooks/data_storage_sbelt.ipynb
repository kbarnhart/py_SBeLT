{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75eaf790-32f3-451c-94f1-46bf2364bfe1",
   "metadata": {},
   "source": [
    "# Working with py_SBeLT's Data Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f385c312-9113-4b5e-b214-575b29022dc6",
   "metadata": {},
   "source": [
    "The `py_SBeLT` model stores data from each run in an .hdf5 file. This notebook will provide a quick walkthrough of _what_ is stored for each run, _where_ it is stored in the .hdf5 file, and _how_ to access the data once a run is complete.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6562d2b6-e376-48b2-8e95-07fe21d66bd2",
   "metadata": {},
   "source": [
    "## What Data is Stored?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47df252-7ea5-48d4-a7e1-98cace58e230",
   "metadata": {},
   "source": [
    "A key data structure in `py_SBeLT` is the particle array. The structure of a particle (implemented as a 1D NumPy array) is the same for every particle. Figure 1 outlines the structure below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291cd01d-c0d0-405d-a7bc-0c850c9c8f26",
   "metadata": {},
   "source": [
    "|![sbelt particle array diagram](particle_array_diagram.png)\n",
    "|:--:|\n",
    "| Figure 1. Diagram of NumPy array representing particles (bed & model) in py_SBeLT. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accb6203-4757-4191-941a-ec673e8c1427",
   "metadata": {},
   "source": [
    "### Per-iteration saves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d755e67-b9b8-4b64-9d02-14c46e7ff2d6",
   "metadata": {},
   "source": [
    "At the end of each iteration the following are saved:\n",
    "- an array of the model particles (`model`)\n",
    "- an array of UIDs representing the event particles (`event_ids`)\n",
    "\n",
    "So if there are 20 iterations in a model run, then there will be 20 model particle arrays saved and 20 event particle arrays saved. Also note that because the structures are saved at the end of an iteration, the array of model particles represents the state of the model particles _after_ entrainment took place during that iteration. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0bf16e-a18b-4ef6-9796-e6f4f40117b4",
   "metadata": {},
   "source": [
    "### Single saves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552a9b39-c47d-46f6-853b-11cafec9a949",
   "metadata": {},
   "source": [
    "Before any iterations take place, the following are saved:\n",
    "- the array of the model particles as they were placed on initialization (`model`)\n",
    "- the array of the bed particles (`bed`)\n",
    "\n",
    "After the iterations have completed the following are saved:\n",
    "- arrays of # of crossings each iteration at each subregion's downstream boundary (`subregion-i-flux`)\n",
    "- array of average age of particles each iteration (`avg_age`)\n",
    "- array of age range of particle each iteration (`age_range`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78ab572-9221-4344-bd10-9db4c69e2e90",
   "metadata": {},
   "source": [
    "## Where is it Stored?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652ad145-c71b-4763-830c-991f24a1d298",
   "metadata": {},
   "source": [
    "All the data mentioned above is written to an `.hdf5` file over the duration of a model run. HDF5 files are composed of Groups and Datasets. Groups can be thought of as folders and Datasets are simply sets of data/data values/structures. To organize the `py_SBeLT data`, there are $4 + N$ groups, where $N$ is the number of iterations.\n",
    "\n",
    "See Figure 1 below for a diagram of the data storage procedure. Blue squares with rounded edges represent Groups, green rectangles represent dataset _names_ and grey ovals represent the actual data stored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a520c258-05d9-4206-a5ba-228e07a0bac2",
   "metadata": {},
   "source": [
    "|![sbelt data storage diagram](sbelt_data_storage.png)\n",
    "|:--:|\n",
    "| Figure 2. Diagram of py_SBeLT's data storage procedure. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0609a38-6585-43d4-ad2d-b04e8be3c71f",
   "metadata": {},
   "source": [
    "## How to Access the Data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dd2dde-6525-41a6-9859-ba45a8cf01a8",
   "metadata": {},
   "source": [
    "To gain better intuition for working with `py_SBeLT`'s data storage, let's run a `sbelt` run and then retrieve some of that stored data and derive some metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fd92ae-e073-4ded-a380-b027dabe1c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sbelt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f8beb4-cfaf-4621-b3cd-fc732eae25a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7c9a28-4147-4927-84f4-8d9806a38106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbelt import sbelt_runner\n",
    "sbelt_runner.run(iterations=100, out_name='data_storage_sbelt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1584a218-0cd5-4ad1-9b5b-db7a5e545f69",
   "metadata": {},
   "source": [
    "### Accessing the Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b1e120-0600-40a9-9999-b23f402aad4a",
   "metadata": {},
   "source": [
    "The first step to accessing the data is to open the desired `.hdf5` file. There are a handful of ways to open a `.hdf5` file, but using a context manager (`with ...`) is useful because we don't have to remember to close the file once we're done out operations. Let's start with opening the file and retrieving some parameters used for the run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2324aff5-9e79-49ad-b429-898f62e758de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This won't get you data!\n",
    "with h5py.File('data_storage_sbelt.hdf5', 'r') as file:\n",
    "    parameters = file['params']\n",
    "    print(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61b0924-7404-4a01-aa93-a210fc807ee4",
   "metadata": {},
   "source": [
    "We can see above that printing the parameters just returns an `HDF5 group`, which tells us we tried to access a Group instead of a Dataset. Let's try again, but instead once we've indexed into the 'params' group we also index for specific parameters: `iterations`, `bed_length`, and `poiss_lambda`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086ec096-0667-40b6-a891-2afd8ea0ef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will get you data!\n",
    "with h5py.File('data_storage_sbelt.hdf5', 'r') as file:\n",
    "    iterations = file['params']['iterations'][()] # add [()] to grab values from a dataset struc \n",
    "    bed_length = file['params']['bed_length'][()]\n",
    "    poiss_lambda = file['params']['poiss_lambda'][()]\n",
    "    print(iterations, bed_length, poiss_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1558e10-d86a-4b86-90ae-4fb811b30951",
   "metadata": {},
   "source": [
    "### Accessing the Model Particle Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec15973-bfd7-4f6a-9c56-1df656ad0a36",
   "metadata": {},
   "source": [
    "Each iteration, the state of all the model particles is saved in an array. Let's access these arrays and compute a sample metric. For an example, let's find the maximum and minimum distance (mm) moved in the stream starting from the end of iteration 12 and ending at the end of iteration 20."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4cec07-a0f5-4cd8-b6c7-12ffa240bf3d",
   "metadata": {},
   "source": [
    "When accessing model particle arrays, take care to note that the iterations are numbered `0...N-1` where `N` is the number of total iterations. So, the second iteration will be at `iteration_1` and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b3c480-3d5a-49f1-a466-cb0aa7a6c52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('data_storage_sbelt.hdf5', 'r') as file:\n",
    "    model_iteration_12 = np.array(file['iteration_11']['model'])\n",
    "    model_iteration_20 = np.array(file['iteration_19']['model'])\n",
    "\n",
    "# x locations are stored in the 0-th index of model particle arrays\n",
    "# See Figure 1\n",
    "iteration_12_x = model_iteration_12[:,0]\n",
    "iteration_20_x = model_iteration_20[:,0]\n",
    "\n",
    "particle_distance_traveled = iteration_20_x - iteration_12_x\n",
    "\n",
    "# Recall that when particle exceed the stream bed they are sent back to the upstream value.\n",
    "# For simplicity, let's ignore those cases and only look at non-looped distances.\n",
    "\n",
    "particle_distance_traveled = particle_distance_traveled[particle_distance_traveled >= 0] # ignore looped distances (negative)\n",
    "particle_max_move = np.max(particle_distance_traveled)\n",
    "particle_min_move = np.min(particle_distance_traveled)\n",
    "\n",
    "\n",
    "print(f'The maximum distance moved was {particle_max_move} mm while the minimum distance was {particle_min_move} mm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1422d843-6b76-4048-bb13-6eb8fda1c893",
   "metadata": {},
   "source": [
    "### Accessing the Final Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0fe14a-6c99-4152-ad63-0a904717fb59",
   "metadata": {},
   "source": [
    "Finally, let's look at accessing the data stored in the `final_metrics` group. The data is the average age of particles per-iteration, the age range of particles per-iteration, and the crossings for each subregion per-iteration. They are all 1D NumPy arrays whose length is $N$ where $N$ is the number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62896fd-f9a4-44ad-a8c4-c424bde695ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c8e847-3c88-4579-b3af-5cd291619ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('data_storage_sbelt.hdf5', 'r') as file:\n",
    "    avg_age = np.array(file['final_metrics']['avg_age'])\n",
    "    age_range = np.array(file['final_metrics']['age_range'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3c53b2-24ba-4a29-94ae-1fa8094c7a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(0, len(avg_age))\n",
    "plt.plot(time, avg_age)\n",
    "plt.xlabel('Numerical Step (Iteration)')\n",
    "plt.ylabel('Average age (# of iterations since last hop)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04ec0b1-0d8c-4806-9173-7731dc6d7939",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time, age_range)\n",
    "plt.xlabel('Numerical Step (Iteration)')\n",
    "plt.ylabel('Age range (Max - min)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f22653b-e7ec-4545-8e99-c725e9790068",
   "metadata": {},
   "source": [
    "Next, let's look at the subregion crossings. As can be seen in Figure 2, the data is stored in a sub-group named `subregions` and the dataset name for each list of crossings is `subregion-i-flux` where $i$ is the subregion of interest. Note that subregions are numbered `0...K-1` where $K$ is the number of subregions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a34ff45-51e4-4056-ba53-ce1743fed29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('data_storage_sbelt.hdf5', 'r') as file:\n",
    "    n_sub = file['params']['num_subregions'][()]\n",
    "    print(n_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adda962-fb22-486c-bd70-d27525660973",
   "metadata": {},
   "source": [
    "There are 4 subregions so we need to use the keys `subregion-0-flux`, `subregion-1-flux`, `subregion-2-flux`, and `subregion-3-flux` to retireve all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc08910-f9d6-4264-8e1e-080b69058ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('data_storage_sbelt.hdf5', 'r') as file:\n",
    "    sub_0_crossing = np.array(file['final_metrics']['subregions']['subregion-0-flux'])\n",
    "    sub_1_crossing = np.array(file['final_metrics']['subregions']['subregion-1-flux'])\n",
    "    sub_2_crossing = np.array(file['final_metrics']['subregions']['subregion-2-flux'])\n",
    "    sub_3_crossing = np.array(file['final_metrics']['subregions']['subregion-3-flux'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898cc734-6617-448a-b9ed-f87dbab5f014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare just subregion 0 and 3 for a simpler visualization\n",
    "plt.plot(time, sub_0_crossing, 'r-', label='subregion 1')\n",
    "plt.plot(time, sub_3_crossing, 'b-', label='subregion 3')\n",
    "plt.legend()\n",
    "plt.xlabel('Numerical Step (Iteration)')\n",
    "plt.ylabel('Number of crossings at downstream boundary')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
